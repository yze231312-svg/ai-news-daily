#!/usr/bin/env python3
"""
AI News Daily - Twitter AI èµ„è®¯èšåˆåç«¯
ä½¿ç”¨ Twitter MCP (via bird CLI) æŠ“å–å®æ—¶èµ„è®¯
"""

import json
import os
import subprocess
import datetime
import random
import sys

# åˆ†ç±»é…ç½®ä¸æœç´¢æŸ¥è¯¢
CATEGORIES = {
    "open_source": {
        "name": "ğŸ”“ å¼€æºé¡¹ç›®",
        "query": "AI open source project (github.com OR huggingface.co) -is:retweet lang:en",
        "icon": "ğŸ”“"
    },
    "tutorial": {
        "name": "ğŸ“– AI æ•™ç¨‹",
        "query": "AI tutorial guide how-to thread -is:retweet lang:en",
        "icon": "ğŸ“–"
    },
    "model": {
        "name": "ğŸ¤– æ¨¡å‹å‘å¸ƒ",
        "query": "new AI model release weights Llama Claude GPT -is:retweet lang:en",
        "icon": "ğŸ¤–"
    },
    "free": {
        "name": "ğŸ†“ å…è´¹èµ„æº",
        "query": "free AI tool access credit API white-prostitute -is:retweet lang:zh",
        "icon": "ğŸ†“"
    },
    "tool": {
        "name": "ğŸ› ï¸ å®ç”¨å·¥å…·",
        "query": "useful AI tool recommendation productivity -is:retweet lang:en",
        "icon": "ğŸ› ï¸"
    }
}

class TwitterFetcher:
    def __init__(self, use_mock=False):
        self.use_mock = use_mock
        self.bird_available = self._check_bird()

    def _check_bird(self):
        try:
            subprocess.run(["bird", "--version"], capture_output=True, check=True)
            return True
        except:
            return False

    def fetch(self, category_key, query):
        if self.use_mock or not self.bird_available:
            return self.generate_mock(category_key)
        
        try:
            # æ‰§è¡Œ bird search å‘½ä»¤è·å– JSON æ ¼å¼ç»“æœ
            # æ³¨æ„ï¼šå®é™…è¿è¡Œæ—¶éœ€è¦ bird å·²é…ç½®å¥½ Twitter cookies
            result = subprocess.run(
                ["bird", "search", "--json", "--count", "10", query],
                capture_output=True, text=True, check=True
            )
            tweets = json.loads(result.stdout)
            return self.process_tweets(tweets, category_key)
        except Exception as e:
            print(f"  âš ï¸ æŠ“å– {category_key} å¤±è´¥: {e}. ä½¿ç”¨ Mock æ•°æ®æ›¿ä»£ã€‚")
            return self.generate_mock(category_key)

    def process_tweets(self, tweets, category_key):
        articles = []
        for t in tweets:
            # å…¼å®¹ bird ä¸åŒç‰ˆæœ¬çš„è¾“å‡ºæ ¼å¼
            tweet_id = t.get("id_str") or str(t.get("id"))
            text = t.get("full_text") or t.get("text") or ""
            user = t.get("user") or {}
            
            articles.append({
                "id": tweet_id,
                "source": "Twitter/X",
                "published_at": t.get("created_at") or datetime.datetime.now().isoformat(),
                "title": self._extract_title(text),
                "content": text,
                "summary": text[:200] + "..." if len(text) > 200 else text,
                "url": f"https://x.com/i/status/{tweet_id}",
                "tags": [h.get("text") for h in t.get("entities", {}).get("hashtags", [])],
                "category": category_key,
                "author": {
                    "username": user.get("screen_name") or "unknown",
                    "display_name": user.get("name") or "Anonymous",
                    "avatar": user.get("profile_image_url_https")
                },
                "metrics": {
                    "likes": t.get("favorite_count", 0),
                    "retweets": t.get("retweet_count", 0),
                    "replies": t.get("reply_count", 0)
                }
            })
        return articles

    def _extract_title(self, text):
        # æå–ç¬¬ä¸€è¡Œæˆ–å‰ 60 ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
        lines = text.split('\n')
        first_line = lines[0].strip()
        if len(first_line) > 80:
            return first_line[:77] + "..."
        return first_line or "AI News Update"

    def generate_mock(self, category_key):
        """ç”Ÿæˆé«˜è´¨é‡çš„æ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿å‰ç«¯é‡æ„æœ‰å†…å®¹å±•ç¤º"""
        now = datetime.datetime.now()
        mocks = {
            "open_source": [
                {
                    "title": "DeepSeek-V3: The New Open Source SOTA",
                    "content": "DeepSeek-V3 is here! Outperforming GPT-4o on many reasoning tasks. Fully open weights and training logs. Check it out: github.com/deepseek-ai/DeepSeek-V3 #AI #OpenSource",
                    "author": "DeepSeek AI", "handle": "deepseek_ai", "likes": 5200, "retweets": 1200
                },
                {
                    "title": "Flux.1: Next-Gen Image Generation",
                    "content": "Black Forest Labs released Flux.1. The details in these images are insane. Better than Midjourney v6? Try it now on HuggingFace. #Flux1 #GenerativeAI",
                    "author": "AI Art Daily", "handle": "ai_art_daily", "likes": 3100, "retweets": 800
                }
            ],
            "tutorial": [
                {
                    "title": "How to deploy Llama 3.3 locally with Ollama",
                    "content": "Thread: ğŸ§µ A complete guide to running the latest Llama 3.3 on your laptop. \n1. Install Ollama\n2. Pull llama3.3:70b\n3. Set up memory optimization...\nFull tutorial here: [Link]",
                    "author": "The AI Guide", "handle": "the_ai_guide", "likes": 1500, "retweets": 450
                }
            ],
            "model": [
                {
                    "title": "Claude 3.7 Opus Rumors heating up",
                    "content": "Rumors suggest Anthropic is preparing to launch Claude 3.7 Opus next week. Expecting massive leaps in coding and agency. #Anthropic #Claude37",
                    "author": "LLM Insights", "handle": "llm_insights", "likes": 2800, "retweets": 600
                }
            ],
            "free": [
                {
                    "title": "Groq: Free API Credits for Developers",
                    "content": "Groq is offering free tier API access for Llama 3.1 405B. The speed is unbelievable (500 t/s). Get your key at groq.com/developers #FreeAI #Groq",
                    "author": "Dev Tools", "handle": "dev_tools", "likes": 4200, "retweets": 1500
                }
            ],
            "tool": [
                {
                    "title": "Cursor AI: The best coding experience in 2026",
                    "content": "Cursor's new 'Tab' feature is basically reading my mind. It's not just auto-complete, it's auto-architecture. #Cursor #CodingAI",
                    "author": "Web Dev Hub", "handle": "webdev_hub", "likes": 2100, "retweets": 300
                }
            ]
        }
        
        category_mocks = mocks.get(category_key, [])
        articles = []
        for i, m in enumerate(category_mocks):
            pub_time = now - datetime.timedelta(hours=random.randint(1, 48))
            articles.append({
                "id": f"mock_{category_key}_{i}",
                "source": "Twitter/X",
                "published_at": pub_time.isoformat(),
                "title": m["title"],
                "content": m["content"],
                "summary": m["content"][:150] + "...",
                "url": f"https://x.com/{m['handle']}/status/{random.randint(100000, 999999)}",
                "tags": ["AI", category_key, "2026"],
                "category": category_key,
                "author": {
                    "username": m["handle"],
                    "display_name": m["author"],
                    "avatar": f"https://ui-avatars.com/api/?name={m['author']}&background=random"
                },
                "metrics": {
                    "likes": m["likes"],
                    "retweets": m["retweets"],
                    "replies": random.randint(10, 200)
                }
            })
        return articles

def main():
    # æ£€æµ‹æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ Mock
    use_mock = "--mock" in sys.argv
    fetcher = TwitterFetcher(use_mock=use_mock) 
    
    print(f"ğŸš€ å¼€å§‹æŠ“å– AI Daily News (Twitter/X)...")
    if fetcher.use_mock:
        print("  ğŸ“ å¤„äº MOCK æ¨¡å¼")
    elif not fetcher.bird_available:
        print("  âš ï¸ æœªæ£€æµ‹åˆ° bird CLIï¼Œå°†è‡ªåŠ¨é™çº§ä¸º MOCK æ¨¡å¼")

    all_articles = []
    category_meta = []
    
    for key, info in CATEGORIES.items():
        print(f"  ğŸ“¥ æ­£åœ¨æŠ“å–: {info['name']}...")
        articles = fetcher.fetch(key, info['query'])
        all_articles.extend(articles)
        category_meta.append({
            "key": key,
            "name": info["name"],
            "icon": info["icon"],
            "count": len(articles)
        })
    
    # æŒ‰å‘å¸ƒæ—¶é—´å€’åºæ’åˆ—
    all_articles.sort(key=lambda x: x['published_at'], reverse=True)
    
    result = {
        "lastUpdate": datetime.datetime.now().strftime("%Y/%m/%d %H:%M"),
        "categories": category_meta,
        "articles": all_articles
    }
    
    # å†™å…¥ data.json
    output_path = "data.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ•°æ®æ›´æ–°å®Œæˆï¼å…±è®¡ {len(all_articles)} æ¡èµ„è®¯ã€‚")
    print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶: {os.path.abspath(output_path)}")

if __name__ == "__main__":
    main()
