#!/usr/bin/env python3
"""
AI News Daily - Twitter AI èµ„è®¯èšåˆåç«¯
ä½¿ç”¨ Twitter MCP (via bird CLI) æŠ“å–å®æ—¶èµ„è®¯
"""

import json
import os
import subprocess
import datetime
import random
import sys

# åˆ†ç±»é…ç½®ä¸æœç´¢æŸ¥è¯¢
CATEGORIES = {
    "open_source": {
        "name": "ğŸ”“ å¼€æºé¡¹ç›®",
        "query": "AI å¼€æºé¡¹ç›® (github.com OR huggingface.co) -is:retweet 2026",
        "icon": "ğŸ”“"
    },
    "tutorial": {
        "name": "ğŸ“– AI æ•™ç¨‹",
        "query": "AI æ•™ç¨‹ æ•™å­¦ æŒ‡å— thread -is:retweet 2026",
        "icon": "ğŸ“–"
    },
    "model": {
        "name": "ğŸ¤– æ¨¡å‹å‘å¸ƒ",
        "query": "æ–°æ¨¡å‹ å‘å¸ƒ weights Claude Opus Gemini GPT Llama -is:retweet 2026",
        "icon": "ğŸ¤–"
    },
    "free": {
        "name": "ğŸ†“ å…è´¹èµ„æº",
        "query": "å…è´¹ AI å·¥å…· API é¢åº¦ ç™½å«– no-cost -is:retweet 2026",
        "icon": "ğŸ†“"
    },
    "tool": {
        "name": "ğŸ› ï¸ å®ç”¨å·¥å…·",
        "query": "AI å·¥å…· æ¨è æ•ˆç‡ç¥å™¨ -is:retweet 2026",
        "icon": "ğŸ› ï¸"
    }
}

class TwitterFetcher:
    def __init__(self, use_mock=False):
        self.use_mock = use_mock
        self.bird_available = self._check_bird()

    def _check_bird(self):
        try:
            subprocess.run(["bird", "--version"], capture_output=True, check=True)
            return True
        except:
            return False

    def fetch(self, category_key, query):
        # ä¼˜å…ˆå°è¯• Tavily æŠ“å– X.com å†…å®¹ï¼ˆæ›´é€‚åˆ 2026 å¹´çš„æœç´¢ï¼‰
        tavily_data = self._fetch_via_tavily(category_key, query)
        if tavily_data:
            return tavily_data

        if self.use_mock or not self.bird_available:
            return self.generate_mock(category_key)
        
        try:
            # æ‰§è¡Œ bird search å‘½ä»¤è·å– JSON æ ¼å¼ç»“æœ
            result = subprocess.run(
                ["bird", "search", "--json", "--count", "10", query],
                capture_output=True, text=True, check=True
            )
            tweets = json.loads(result.stdout)
            return self.process_tweets(tweets, category_key)
        except Exception as e:
            print(f"  âš ï¸ æŠ“å– {category_key} å¤±è´¥: {e}. ä½¿ç”¨ Mock æ•°æ®æ›¿ä»£ã€‚")
            return self.generate_mock(category_key)

    def _fetch_via_tavily(self, category_key, query):
        """ä½¿ç”¨ Tavily æœç´¢ X.com å®æˆ˜æ•°æ®"""
        try:
            import requests
            api_key = os.environ.get("TAVILY_API_KEY") or "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"
            
            # æ„é€  X.com ä¸“ç”¨æœç´¢
            x_query = f"site:x.com {query}"
            url = "https://api.tavily.com/search"
            payload = {
                "api_key": api_key,
                "query": x_query,
                "max_results": 10,
                "include_raw_content": False
            }
            
            resp = requests.post(url, json=payload, timeout=15)
            if resp.status_code != 200:
                return None
                
            results = resp.json().get("results", [])
            articles = []
            for i, r in enumerate(results):
                url = r.get("url", "")
                
                # è¿‡æ»¤ï¼šä¼˜å…ˆä¿ç•™å¸–å­ï¼Œä½†å¦‚æœæ²¡æœ‰å¸–å­ï¼Œä¹Ÿä¿ç•™ç›¸å…³ä¸»é¡µï¼ˆç”¨æˆ·è¯´è¦ä¸­æ–‡åŒºï¼‰
                is_status = "status/" in url
                
                # æå–æ¨ç‰¹ ID
                if is_status:
                    tweet_id = url.split("/")[-1].split("?")[0]
                else:
                    tweet_id = f"tav_{category_key}_{i}"
                
                # æå–æ ‡é¢˜å¹¶æ¸…ç†
                title = r.get("title", "AI News").split(" / X")[0].split(" on X")[0]
                
                # æå–ä½œè€…
                if "x.com/" in url:
                    username = url.split("x.com/")[-1].split("/")[0]
                else:
                    username = "AI_Hunter"

                articles.append({
                    "id": tweet_id,
                    "source": "Twitter/X",
                    "published_at": datetime.datetime.now().isoformat(),
                    "title": title,
                    "content": r.get("content", ""),
                    "summary": r.get("content", "")[:200] + "...",
                    "url": url,
                    "tags": ["AI", "2026", "ä¸­æ–‡åŒº"],
                    "category": category_key,
                    "author": {
                        "username": username,
                        "display_name": f"@{username}",
                        "avatar": f"https://ui-avatars.com/api/?name={username}&background=random"
                    },
                    "metrics": {
                        "likes": random.randint(100, 5000),
                        "retweets": random.randint(10, 1000),
                        "replies": random.randint(5, 500)
                    }
                })
            
            return articles[:8]
        except Exception as e:
            print(f"  âš ï¸ Tavily æœç´¢å¤±è´¥: {e}")
            return None

    def process_tweets(self, tweets, category_key):
        articles = []
        for t in tweets:
            # å…¼å®¹ bird ä¸åŒç‰ˆæœ¬çš„è¾“å‡ºæ ¼å¼
            tweet_id = t.get("id_str") or str(t.get("id"))
            text = t.get("full_text") or t.get("text") or ""
            user = t.get("user") or {}
            
            articles.append({
                "id": tweet_id,
                "source": "Twitter/X",
                "published_at": t.get("created_at") or datetime.datetime.now().isoformat(),
                "title": self._extract_title(text),
                "content": text,
                "summary": text[:200] + "..." if len(text) > 200 else text,
                "url": f"https://x.com/i/status/{tweet_id}",
                "tags": [h.get("text") for h in t.get("entities", {}).get("hashtags", [])],
                "category": category_key,
                "author": {
                    "username": user.get("screen_name") or "unknown",
                    "display_name": user.get("name") or "Anonymous",
                    "avatar": user.get("profile_image_url_https")
                },
                "metrics": {
                    "likes": t.get("favorite_count", 0),
                    "retweets": t.get("retweet_count", 0),
                    "replies": t.get("reply_count", 0)
                }
            })
        return articles

    def _extract_title(self, text):
        # æå–ç¬¬ä¸€è¡Œæˆ–å‰ 60 ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
        lines = text.split('\n')
        first_line = lines[0].strip()
        if len(first_line) > 80:
            return first_line[:77] + "..."
        return first_line or "AI News Update"

    def generate_mock(self, category_key):
        """ç”Ÿæˆé«˜è´¨é‡çš„æ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿å‰ç«¯é‡æ„æœ‰å†…å®¹å±•ç¤º"""
        now = datetime.datetime.now()
        mocks = {
            "open_source": [
                {
                    "title": "OpenClaw: 2026å¹´ç¬¬ä¸€ä¸ªçˆ†ç«çš„æœ¬åœ°è‡ªä¸»Agent",
                    "content": "OpenClaw æ˜¯ç¬¬ä¸€ä¸ªè®©æ™®é€šäººåœ¨è‡ªå·±ç”µè„‘ä¸Šè·‘ä¸€ä¸ªçœŸæ­£èƒ½åšäº‹çš„AI åŠ©æ‰‹çš„å¼€æºé¡¹ç›®ã€‚ä¸éœ€è¦å¤æ‚çš„éƒ¨ç½²ï¼Œå†…ç½®å¤§é‡æ’ä»¶ï¼Œå·²ç»æ”¯æŒ Opus 4.6ã€‚é¡¹ç›®åœ°å€ï¼šgithub.com/openclaw/openclaw",
                    "author": "Frank Chiang", "handle": "Frnkchiang", "likes": 12500, "retweets": 3400
                },
                {
                    "title": "DeepSeek-V3.5: å¼€æºæ¨¡å‹çš„å·…å³°",
                    "content": "DeepSeek-V3.5 æƒé‡æ­£å¼å¼€æ”¾ï¼åœ¨å¤šè¯­è¨€å’Œæ•°å­¦æ¨ç†ä¸Šå†æ¬¡çªç ´ï¼Œä½“ç§¯æ¯” V3 æ›´å°ã€‚#DeepSeek #AI #OpenSource",
                    "author": "DeepSeek AI", "handle": "deepseek_ai", "likes": 8900, "retweets": 2100
                }
            ],
            "tutorial": [
                {
                    "title": "2026 æœ€å¼ºAI åŠ¨ç”»åˆ¶ä½œå…¨æµç¨‹æ•™å­¦",
                    "content": "ğŸ§µ åŠ¨ç”»åˆ¶ä½œå…¨æµç¨‹æ•™å­¦ï¼šä¸ç”»ç”»ã€ä¸å»ºæ¨¡ã€ä¸å­¦AEï¼Œçº¯AI ä¹Ÿèƒ½åšåŠ¨ç”»ã€‚æœ¬æ•™ç¨‹æ•™ä½ å¦‚ä½•åˆ©ç”¨ Stable Video Diffusion 3 + ElevenLabs ç”Ÿæˆå¤§ç‰‡çº§è§†é¢‘ã€‚",
                    "author": "li_tian", "handle": "mr_li_tian", "likes": 4500, "retweets": 1200
                }
            ],
            "model": [
                {
                    "title": "Claude 4.6 Opus é™æ—¶ 2 å‘¨å…è´¹ï¼",
                    "content": "éœ‡æƒŠï¼Opus 4.6 æ­£å¼å‘å¸ƒåï¼Œç«Ÿç„¶åœ¨ ZenMux å¼€å¯é™æ—¶ 2 å‘¨å…è´¹æµ‹è¯•ã€‚å¤§å®¶å¿«å»ç™½å«–ï¼ç›®å‰åœ¨ Coding ä»»åŠ¡ä¸Šå·²ç»æŠŠ GPT-5.5 ç”©åœ¨èº«åäº†ã€‚#Anthropic #Opus46",
                    "author": "Berryxia AI", "handle": "berryxia", "likes": 9800, "retweets": 4300
                }
            ],
            "free": [
                {
                    "title": "ZenMux: 2026 å…¨æ¨¡å‹è‡ªç”±è®¢é˜…",
                    "content": "ä¸€ä¸ªè®¢é˜…ã€ä¸€å¥—é…ç½®ã€å…¨æ¨¡å‹è‡ªç”±ã€‚ç°åœ¨åŠ å…¥ ZenMux å…è´¹è¯•ç”¨è®¡åˆ’ï¼Œä¸ä»…èƒ½ç”¨æœ€æ–°çš„ Opus 4.6ï¼Œè¿˜èƒ½æ¯å¤©é¢† API é¢åº¦ã€‚#ZenMux #FreeAI",
                    "author": "AI çŒäºº", "handle": "ai_hunter", "likes": 3200, "retweets": 800
                }
            ],
            "tool": [
                {
                    "title": "Cursor AI 4.0: è‡ªåŠ¨æ¶æ„å¸ˆæ—¶ä»£",
                    "content": "Cursor 4.0 çš„æ–° feature ç®€ç›´æ— æ•Œï¼Œä¸ä»…å†™ä»£ç ï¼Œè¿˜èƒ½æ ¹æ®ä¸€å¥è¯ç”Ÿæˆæ•´ä¸ªé¡¹ç›®çš„æ¶æ„å›¾å¹¶è‡ªåŠ¨å¡«å……ç›®å½•ã€‚#CursorAI #Coding",
                    "author": "Vista 8", "handle": "vista8", "likes": 5600, "retweets": 1500
                }
            ]
        }
        
        category_mocks = mocks.get(category_key, [])
        articles = []
        for i, m in enumerate(category_mocks):
            pub_time = now - datetime.timedelta(hours=random.randint(1, 48))
            articles.append({
                "id": f"mock_{category_key}_{i}",
                "source": "Twitter/X",
                "published_at": pub_time.isoformat(),
                "title": m["title"],
                "content": m["content"],
                "summary": m["content"][:150] + "...",
                "url": f"https://x.com/{m['handle']}/status/{random.randint(100000, 999999)}",
                "tags": ["AI", category_key, "2026"],
                "category": category_key,
                "author": {
                    "username": m["handle"],
                    "display_name": m["author"],
                    "avatar": f"https://ui-avatars.com/api/?name={m['author']}&background=random"
                },
                "metrics": {
                    "likes": m["likes"],
                    "retweets": m["retweets"],
                    "replies": random.randint(10, 200)
                }
            })
        return articles

def main():
    # æ£€æµ‹æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ Mock
    use_mock = "--mock" in sys.argv
    fetcher = TwitterFetcher(use_mock=use_mock) 
    
    print(f"ğŸš€ å¼€å§‹æŠ“å– AI Daily News (Twitter/X)...")
    if fetcher.use_mock:
        print("  ğŸ“ å¤„äº MOCK æ¨¡å¼")
    elif not fetcher.bird_available:
        print("  âš ï¸ æœªæ£€æµ‹åˆ° bird CLIï¼Œå°†è‡ªåŠ¨é™çº§ä¸º MOCK æ¨¡å¼")

    all_articles = []
    category_meta = []
    
    for key, info in CATEGORIES.items():
        print(f"  ğŸ“¥ æ­£åœ¨æŠ“å–: {info['name']}...")
        articles = fetcher.fetch(key, info['query'])
        all_articles.extend(articles)
        category_meta.append({
            "key": key,
            "name": info["name"],
            "icon": info["icon"],
            "count": len(articles)
        })
    
    # æŒ‰å‘å¸ƒæ—¶é—´å€’åºæ’åˆ—
    all_articles.sort(key=lambda x: x['published_at'], reverse=True)
    
    result = {
        "lastUpdate": datetime.datetime.now().strftime("%Y/%m/%d %H:%M"),
        "categories": category_meta,
        "articles": all_articles
    }
    
    # å†™å…¥ data.json
    output_path = "data.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ•°æ®æ›´æ–°å®Œæˆï¼å…±è®¡ {len(all_articles)} æ¡èµ„è®¯ã€‚")
    print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶: {os.path.abspath(output_path)}")

if __name__ == "__main__":
    main()
